{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBOOST "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble은 정확도가 낮은 여러가지 모델들을 결합하여 더 높은 정확도를 이끌어내는데 쓰이는 모델이다.  \n",
    "Ensemble에는 bagging과 boosting이 포함되어 있다.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Boosting에는 GBM이라는 모델이 있다. 이 모델의 단점은 느리다는 것과 overfitting의 위험이 있다는 점이다.  \n",
    "그래서 이 단점들을 보완하기 위하여 XGBOOST라는 모델이 나왔다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBOOST의 특징은 다음과 같다.\n",
    "1. gbm보다 빠르다\n",
    "2. overfitting 방지가 가능한 규제가 포함되어 있다.\n",
    "3. 분류와 회귀가 둘 다 가능하다.\n",
    "4. 조기 종료(early stopping)을 지원한다.\n",
    "5. Gradient boosting을 기반으로 하기에 앙상블 부스팅의 특징인 가중체 부여를 경사하강법으로 한다.\n",
    "6. 뛰어난 예측 성능\n",
    "7. 자체 내장된 교차검증\n",
    "- 반복 수행마다 내부적으로 교차검증 수행-최적화된 반복 수행횟수를 가질 수 있다.\n",
    "- 지정된 반복 횟수가 아니라 교차검증을 통해 평가 데이트세트의 평가 값이 최적화되면 반복을 중간에 멈출 수 있는 기능이 있다.\n",
    "8. 결측값 자체 처리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGboost의 parameter\n",
    "1. n_estimators(결정트리의 개수)\n",
    "2. max_depth(트리의 깊이)\n",
    "3. colsample_bytree(컬럼의 샘플링 비율)\n",
    "4. subsample(weak learner가 학습에 사용하는 데이터 샘플링 비율)\n",
    "5. learning_rate(학습률)\n",
    "6. min_split_loss(리프 노드를 추가적으로 나눌지 결정하는 값)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
